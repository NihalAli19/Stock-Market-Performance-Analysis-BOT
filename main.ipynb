{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf3fb73c6970b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T04:31:00.630624500Z",
     "start_time": "2023-11-30T04:30:57.537784900Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_objects\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgo\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MinMaxScaler\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense, Dropout, LSTM\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m timedelta\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from datetime import timedelta\n",
    "\n",
    "df = pd.read_csv(\"TSLA.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=df[\"Date\"],\n",
    "                                     open=df['Open'],\n",
    "                                     high=df['High'],\n",
    "                                     low=df['Low'],\n",
    "                                     close=df['Close'])])\n",
    "fig.show()\n",
    "\n",
    "data = df.dropna()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_Data = scaler.fit_transform(data[\"Close\"].values.reshape(-1, 1))\n",
    "\n",
    "timetopredict = 90\n",
    "\n",
    "xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "for x in range(timetopredict, len(scaled_Data)):\n",
    "\txtrain.append(scaled_Data[x - timetopredict:x, 0])\n",
    "\tytrain.append(scaled_Data[x, 0])\n",
    "\n",
    "xtrain = np.array(xtrain)\n",
    "ytrain = np.array(ytrain)\n",
    "\n",
    "xtrain = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[1], 1))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(xtrain.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=25, batch_size=32)\n",
    "\n",
    "test_start_date = data[\"Date\"].iloc[-timetopredict]\n",
    "test_data = data[data[\"Date\"] >= test_start_date]\n",
    "test_data = pd.merge(data[\"Close\"], test_data)\n",
    "\n",
    "actual_test_price = test_data[\"Close\"].values\n",
    "\n",
    "total_dataset = pd.concat((data[\"Close\"], test_data[\"Close\"]), axis=0)\n",
    "\n",
    "input_models = total_dataset[len(total_dataset) - len(test_data) - timetopredict:].values\n",
    "input_models = input_models.reshape((-1, 1))\n",
    "input_models = scaler.transform(input_models)\n",
    "\n",
    "xtest = []\n",
    "\n",
    "for x in range(timetopredict, len(input_models)):\n",
    "\txtest.append(input_models[x - timetopredict:x, 0])\n",
    "\n",
    "xtest = np.array(xtest)\n",
    "xtest = np.reshape(xtest, (xtest.shape[0], xtest.shape[1], 1))\n",
    "\n",
    "testprice = model.predict(xtest)\n",
    "\n",
    "testprice = scaler.inverse_transform(testprice)\n",
    "\n",
    "plt.plot(actual_test_price,label = \"real\")\n",
    "plt.plot(testprice,label = \"predict\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# Get the last date in the dataset\n",
    "last_date = data[\"Date\"].max()\n",
    "\n",
    "# Generate future dates for the next 90 days\n",
    "future_dates = [last_date + timedelta(days=i) for i in range(1, 91)]\n",
    "\n",
    "# Use the last `timetopredict` days from the dataset as input for prediction\n",
    "input_future = total_dataset[-timetopredict:].values\n",
    "input_future = input_future.reshape((-1, 1))\n",
    "input_future = scaler.transform(input_future)\n",
    "\n",
    "x_future = []\n",
    "\n",
    "# Create input data for the next 90 days\n",
    "for i in range(timetopredict, timetopredict + 90):\n",
    "    x_future.append(input_future[i - timetopredict:i, 0])\n",
    "\n",
    "# Ensure that all arrays in x_future have the same length\n",
    "max_len = max(len(arr) for arr in x_future)\n",
    "x_future = [np.pad(arr, (0, max_len - len(arr))) for arr in x_future]\n",
    "\n",
    "# Concatenate the arrays to create the input for LSTM\n",
    "x_future = np.concatenate(x_future, axis=0)\n",
    "\n",
    "# Reshape for LSTM input (samples, time steps, features)\n",
    "x_future = np.reshape(x_future, (int(x_future.shape[0] / timetopredict), timetopredict, 1))\n",
    "\n",
    "# Predict future stock prices\n",
    "future_predictions = model.predict(x_future)\n",
    "\n",
    "# Inverse transform the predictions to the original scale\n",
    "future_predictions = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "# Plot historical data\n",
    "plt.plot(data[\"Date\"], data[\"Close\"], label=\"Historical Data\")\n",
    "\n",
    "# Plot predicted prices for the next 90 days\n",
    "plt.plot(future_dates, future_predictions, label=\"Future Predictions\")\n",
    "\n",
    "plt.title('Historical and Future Stock Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
